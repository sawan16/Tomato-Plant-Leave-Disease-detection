{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "tomato_classification",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aEQNMnnTxsv"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wor_XlijQGwS"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from shutil import copyfile\n",
        "import cv2\n",
        "import numpy as np\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ASTF98eQoxi"
      },
      "source": [
        "categories = os.listdir('data/Tomato_data/testing')\n",
        "\n",
        "for c in categories:\n",
        "  print(len(os.listdir('data/Tomato_data/testing/'+c+'/')), len(os.listdir('data/Tomato_data/training/'+c+'/')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wNCvPWg7WFZ"
      },
      "source": [
        "img_size = 256\n",
        "def get_data(data_dir):\n",
        "    data = [] \n",
        "    for label in categories: \n",
        "        path = os.path.join(data_dir, label)\n",
        "        class_num = categories.index(label)\n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "                img_arr = cv2.imread(os.path.join(path, img))#[...,::-1] #convert BGR to RGB format\n",
        "                resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size\n",
        "                data.append([resized_arr, class_num])\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "    return np.array(data)\n",
        "\n",
        "train = get_data('data/Tomato_data/training')\n",
        "val = get_data('data/Tomato_data/testing')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Bo90--VLU8r",
        "outputId": "9c3e07de-8b00-45b8-9f70-3f35524c1d28"
      },
      "source": [
        "categories"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Bacterial_Spot',\n",
              " 'Early_Blight',\n",
              " 'Healthy',\n",
              " 'Late_Blight',\n",
              " 'Leaf_Mold',\n",
              " 'Mosaic_Virus',\n",
              " 'Septoria_Leaf_Spot',\n",
              " 'Spider_Mites',\n",
              " 'Target_Spot',\n",
              " 'Yellow_Leaf_Curl_Virus']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLHVOM4qIL3M"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def display_multiple_img(images, rows = 1, cols=1):\n",
        "    figure, ax = plt.subplots(nrows=rows,ncols=cols, figsize=(10,5) )\n",
        "    for ind,title in enumerate(images):\n",
        "        ax.ravel()[ind].imshow(images[title])\n",
        "        ax.ravel()[ind].set_title(title)\n",
        "        ax.ravel()[ind].set_axis_off()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "total_images = 10\n",
        "labels = categories\n",
        "images = {labels[val[i*20][1]]: val[i*20][0] for i in range(total_images)}\n",
        "\n",
        "display_multiple_img(images, 2, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDIEamo18Owh"
      },
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "x_val = []\n",
        "y_val = []\n",
        "\n",
        "for feature, label in train:\n",
        "  x_train.append(feature)\n",
        "  y_train.append(label)\n",
        "\n",
        "for feature, label in val:\n",
        "  x_val.append(feature)\n",
        "  y_val.append(label)\n",
        "\n",
        "# Normalize the data\n",
        "x_train = np.array(x_train) / 255\n",
        "x_val = np.array(x_val) / 255\n",
        "\n",
        "x_train.reshape(-1, img_size, img_size, 1)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "x_val.reshape(-1, img_size, img_size, 1)\n",
        "y_val = np.array(y_val)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJUk481bQ1C_"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout \n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "#from keras.optimizers import Adam\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(128,3,padding=\"same\", activation=\"relu\", input_shape=(256,256,3)))\n",
        "model.add(MaxPool2D())\n",
        "\n",
        "model.add(Conv2D(32, 3, padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D())\n",
        "\n",
        "model.add(Conv2D(64, 3, padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D())\n",
        "\n",
        "model.add(Conv2D(64, 3, padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256,activation=\"relu\"))\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model.summary()\n",
        "#opt = Adam(lr=0.0001)\n",
        "model.compile(optimizer = 'Adam' , loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) , metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPMJcZU-_UHC"
      },
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='model.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blTa2myR8YMq"
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        #rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.2, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        #horizontal_flip = True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaASMCskSdvR"
      },
      "source": [
        "history = model.fit(x_train,y_train,epochs = 200, validation_data = (x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmyApa2rWgst"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(200)\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss', fontdict={'size':20})\n",
        "#plt.show()\n",
        "plt.savefig('cnn_loss-acc.png',bbox_inches = 'tight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biZGdtbn1yz4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "epochs_range = range(200)\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(15,6))\n",
        "plt.rc('xtick', labelsize=10)    # fontsize of the tick labels\n",
        "plt.rc('ytick', labelsize=10)\n",
        "ax1.plot(epochs_range, acc, label='Training Accuracy', c = '#4CAF50', linewidth=4)\n",
        "ax1.plot(epochs_range, val_acc, label='Validation Accuracy', c='red', linewidth=4)\n",
        "ax1.legend()\n",
        "ax1.set_title('Training and Validation Accuracy',fontsize=18)\n",
        "ax1.set_ylabel('Accuracy',fontsize=18)\n",
        "ax1.set_xlabel('Epoch',fontsize=18)\n",
        "\n",
        "ax2.plot(epochs_range, loss, label='Training Loss',c = '#4CAF50', linewidth=4)\n",
        "ax2.plot(epochs_range, val_loss, label='Validation Loss', c='red', linewidth=4)\n",
        "ax2.legend()\n",
        "ax2.set_title('Training and Validation Loss',fontsize=18)\n",
        "ax2.set_ylabel('Loss',fontsize=18)\n",
        "ax2.set_xlabel('Epoch',fontsize=18)\n",
        "fig.tight_layout(pad=3.0)\n",
        "#plt.show()\n",
        "plt.savefig('plot1.png',bbox_inches = 'tight')\n",
        "plt.clf()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJF9U-tQXS20"
      },
      "source": [
        "predictions = np.argmax(model.predict(x_val), axis=1)\n",
        "#predictions = predictions.reshape(1,-1)[0]\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "print(classification_report(y_val, predictions, target_names = categories))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEkmw8aV6Vgn"
      },
      "source": [
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "cm1 = confusion_matrix(y_val, predictions)\n",
        "df_cm = pd.DataFrame(cm1, index = [i for i in categories],\n",
        "              columns = [i for i in categories])\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.heatmap(df_cm, annot=True,cmap=\"RdPu\")\n",
        "plt.savefig('confusion_mrtx1.png',bbox_inches = 'tight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYgLSeXB5XVI"
      },
      "source": [
        "## Transfer Learning..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2g-hItgVHxY"
      },
      "source": [
        "base_model = tf.keras.applications.MobileNetV2(input_shape = (256, 256, 3), include_top = False, weights = \"imagenet\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWj0fDkfVJqY"
      },
      "source": [
        "base_model.trainable = False\n",
        "model = tf.keras.Sequential([base_model,\n",
        "                                 tf.keras.layers.GlobalAveragePooling2D(),\n",
        "                                 tf.keras.layers.Dropout(0.2),\n",
        "                                 tf.keras.layers.Dense(20, activation=\"softmax\")                                     \n",
        "                                ])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXn6oC86-wEK"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTWKJ6qAVTWI"
      },
      "source": [
        "base_learning_rate = 0.0001\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history1 = model.fit(x_train,y_train,epochs = 200 , validation_data = (x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfsNyB24VcVg"
      },
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "acc1 = history1.history['accuracy']\n",
        "val_acc1 = history1.history['val_accuracy']\n",
        "loss1 = history1.history['loss']\n",
        "val_loss1 = history1.history['val_loss']\n",
        "\n",
        "epochs_range = range(200)\n",
        "\n",
        "plt.figure(figsize=(25, 15))\n",
        "plt.subplot(2, 2, 1)\n",
        "\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.plot(epochs_range, acc1, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc1, label='Validation Accuracy')\n",
        "\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.plot(epochs_range, loss1, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss1, label='Validation Loss')\n",
        "\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "#plt.savefig('tnrfr_cnn_loss-acc.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e844Rz1F8N4O"
      },
      "source": [
        "epochs_range = range(200)\n",
        "import matplotlib.pyplot as plt\n",
        "acc1 = history1.history['accuracy']\n",
        "val_acc1 = history1.history['val_accuracy']\n",
        "loss1 = history1.history['loss']\n",
        "val_loss1 = history1.history['val_loss']\n",
        "\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(15,6))\n",
        "plt.rc('xtick', labelsize=10)    # fontsize of the tick labels\n",
        "plt.rc('ytick', labelsize=10)\n",
        "ax1.plot(epochs_range, acc, label='CNN Training Accuracy', c = '#4CAF50', linewidth=4)\n",
        "ax1.plot(epochs_range, val_acc, label='CNN Validation Accuracy', c='red', linewidth=4)\n",
        "ax1.plot(epochs_range, acc1, label='Transfer learning Training Accuracy', c = '#e72866', linewidth=4)\n",
        "ax1.plot(epochs_range, val_acc1, label='Transfer learning Validation Accuracy', c='#282ec7', linewidth=4)\n",
        "\n",
        "ax1.legend()\n",
        "ax1.set_title('Training and Validation Accuracy',fontsize=18)\n",
        "ax1.set_ylabel('Accuracy',fontsize=18)\n",
        "ax1.set_xlabel('Epoch',fontsize=18)\n",
        "\n",
        "ax2.plot(epochs_range, loss, label='CNN Training Loss',c = '#4CAF50', linewidth=4)\n",
        "ax2.plot(epochs_range, val_loss, label='CNN Validation Loss', c='red', linewidth=4)\n",
        "ax2.plot(epochs_range, loss1, label='Transfer learning Training Loss',c = '#c72866', linewidth=4)\n",
        "ax2.plot(epochs_range, val_loss1, label='Transfer learning Validation Loss', c='#282ec7', linewidth=4)\n",
        "\n",
        "ax2.legend()\n",
        "ax2.set_title('Training and Validation Loss',fontsize=18)\n",
        "ax2.set_ylabel('Loss',fontsize=18)\n",
        "ax2.set_xlabel('Epoch',fontsize=18)\n",
        "fig.tight_layout(pad=3.0)\n",
        "#plt.show()\n",
        "plt.savefig('plot2.png',bbox_inches = 'tight')\n",
        "plt.clf()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uK36fFtwVpSg"
      },
      "source": [
        "predictions = np.argmax(model.predict(x_val), axis=1)\n",
        "#predictions = predictions.reshape(1,-1)[0]\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "print(classification_report(y_val, predictions, target_names = categories))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHmUZsHlALsq"
      },
      "source": [
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "cm2 = confusion_matrix(y_val, predictions)\n",
        "df_cm = pd.DataFrame(cm2, index = [i for i in categories],\n",
        "              columns = [i for i in categories])\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.heatmap(df_cm, annot=True,cmap=\"RdPu\")\n",
        "plt.savefig('confusion_mrtx2.png',bbox_inches = 'tight')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}